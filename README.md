# Lovelace Code ðŸš€

**Lovelace Code** is a **terminal-first, model-agnostic agentic coding environment** designed for developers who want powerful AI assistance **without being locked to a single model or vendor**.

It provides a lightweight local runtime where **any capable language model**â€”open or proprietaryâ€”can act as a software agent through a shared tool interface, with persistent per-repository state.

> Think *Claude Code*, but **vendor-independent**, **local-first**, and **extensible by design**.

---

## Why Lovelace? ðŸ§ 

Most AI coding tools hard-wire:
- a single provider
- a fixed UX
- opaque agent logic

Lovelace flips the stack:

```

Tool Runtime (stable)
â””â”€ Agent Protocol
â””â”€ Interchangeable Models

```

Models are engines.  
Lovelace is the runtime.

---

## Core Features âœ¨

- **Terminal-first agentic workflow** â€” no IDE lock-in
- **Model-agnostic architecture** (local + API backends)
- **Per-repo persistent state** stored under `.lovelace/`
- **Pluggable backends** for Hugging Face and hosted APIs
- **Fast iteration loop** for coding, refactoring, debugging
- **Minimal surface area** â€” easy to extend, easy to reason about

---

## Default Local Models ðŸ§©

Out of the box, Lovelace ships with open, local-friendly models:

- `Spestly/Lovelace-1-3B` â€” fast, efficient coding assistant
- `Spestly/Lovelace-1-7B` â€” more capable reasoning and code generation

These are ideal for:
- local development
- offline workflows
- experimentation without API costs

---

## API / Hosted Models (Optional) ðŸŒ

Lovelace can also interface with **state-of-the-art hosted models** via optional API backends.

These models are **not required** â€” they are simply additional engines Lovelace can drive.

> Proprietary APIs are treated as interchangeable backends, not dependencies.

```

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Model ID                â”‚ Provider  â”‚      Size â”‚ Context â”‚ Description                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â— Spestly/Lovelace-1-3B â”‚    HF     â”‚        3B â”‚      4K â”‚ Fast, efficient coding assistant         â”‚
â”‚ â˜… Spestly/Lovelace-1-7B â”‚    HF     â”‚        7B â”‚      4K â”‚ More capable coding assistant            â”‚
â”‚ â˜… gpt-5.2-pro           â”‚  OpenAI   â”‚  Flagship â”‚    256K â”‚ High-capability general reasoning        â”‚
â”‚ gpt-5.2-thinking        â”‚  OpenAI   â”‚  Flagship â”‚    256K â”‚ Reasoning-focused variant                â”‚
â”‚ gpt-5.2-instant         â”‚  OpenAI   â”‚      Fast â”‚    128K â”‚ Low-latency, cost-efficient              â”‚
â”‚ â˜… o4-mini               â”‚  OpenAI   â”‚ Efficient â”‚    128K â”‚ Efficient reasoning (o-series)           â”‚
â”‚ â˜… claude-opus-4.5       â”‚ Anthropic â”‚  Flagship â”‚    200K â”‚ Top-tier reasoning + tool use            â”‚
â”‚ â˜… claude-sonnet-4.5     â”‚ Anthropic â”‚  Balanced â”‚    200K â”‚ Balanced reasoning and speed             â”‚
â”‚ claude-haiku-4.5        â”‚ Anthropic â”‚     Light â”‚    200K â”‚ Lightweight, fast variant                â”‚
â”‚ â˜… gemini-3-pro          â”‚  Google   â”‚  Flagship â”‚      1M â”‚ Large-context multimodal reasoning       â”‚
â”‚ gemini-3-flash          â”‚  Google   â”‚      Fast â”‚      1M â”‚ Faster, cheaper Gemini variant           â”‚
â”‚ â˜… grok-4                â”‚    xAI    â”‚     Large â”‚    128K â”‚ General reasoning + real-time focus      â”‚
â”‚ â˜… glm-4.7               â”‚   Zhipu   â”‚     Large â”‚    128K â”‚ Strong coding and reasoning              â”‚
â”‚ glm-4.6v-flash          â”‚   Zhipu   â”‚      Fast â”‚    128K â”‚ Efficient multimodal variant             â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

````

---

## Quickstart (Development) ðŸ’»

From the repository root:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e .
````

Enable Lovelace in any project:

```bash
lovelace init
lovelace
```

This creates a `.lovelace/` directory and starts an interactive agent session.

---

## Commands ðŸ§­

* `lovelace init` â€” initialize repo-scoped Lovelace state
* `lovelace` â€” start an interactive agent session

Inside a session:

* `/model` â€” switch the active model backend
* `/config` â€” inspect runtime configuration

---

## Project State & Files ðŸ“

Each repository using Lovelace contains a `.lovelace/` folder:

* `.lovelace/config.json` â€” per-repo configuration
* `.lovelace/activity.log` â€” chronological action log
* `.lovelace/memory.md` â€” lightweight long-term agent memory

This keeps agent context **local, inspectable, and version-controllable**.

---

## Backends & Extensibility ðŸ”§

Backend implementations live under:

```
src/lovelace_code/backends/
```

To add a new backend:

1. Implement the backend interface
2. Register it in `backends/registry.py`
3. Add basic tests for expected behavior

Lovelace is intentionally minimal to make backend development trivial.

---

## Troubleshooting âš ï¸

* Ensure required API tokens are set (e.g. `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`)
* Check `.lovelace/activity.log` for recent errors
* Inspect backend implementations for model-specific issues

---

## Philosophy ðŸ§©

Lovelace Code is built around one principle:

> **Agentic tooling should outlive models.**

Models will change.
Vendors will change.
The runtime should not.

---

## License & Contributions ðŸ“œ

Add a `LICENSE` file if publishing publicly.

Contributions are welcome:

* new backends
* tooling improvements
* protocol refinements

Open an issue or PR to discuss changes.

---

*Lovelace Code â€” vendor-independent agentic AI for developers who care about control.* ðŸ’¡
